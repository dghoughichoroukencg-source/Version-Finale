

# üìò COMPTE RENDU : ANALYSE DU PROJET DATA SCIENCE (CYBERS√âCURIT√â)

![WhatsApp Image 2025-10-27 √† 13 39 11_c6ff40d2](https://github.com/user-attachments/assets/b394e0fd-933c-49ff-a8f4-046bf238ea93)













Chorouk dghoughi
22006691

## 1. Le Contexte M√©tier et la Mission

### Le Probl√®me (Business Case)
Nous sommes ici face √† un enjeu de **Cybers√©curit√© Mondiale**. Les entreprises et gouvernements subissent des attaques vari√©es g√©n√©rant des pertes financi√®res massives.
* **Objectif :** Cr√©er un mod√®le d'IA capable de classifier/pr√©dire la nature de la menace (la Cible comporte ici **72 classes** distinctes, ce qui est beaucoup plus complexe qu'un probl√®me binaire).
* **L'Enjeu critique :** Identifier correctement le type d'attaque ou l'attaquant permet d'activer la bonne strat√©gie de d√©fense (ex: Firewall vs IA-based detection) et de minimiser les pertes financi√®res et le vol de donn√©es.

### Les Donn√©es (L'Input)
Le dataset analys√© dans le notebook contient **3000 observations** et **10 colonnes**.
* **Features (X) :** Variables mixtes incluant l'ann√©e (`Year`), les pertes financi√®res (`Financial Loss`), le nombre d'utilisateurs affect√©s, etc.
* **Target (y) :** Une variable cat√©gorielle tr√®s fragment√©e avec **72 classes uniques**, ce qui rend la t√¢che de classification particuli√®rement ardue pour un mod√®le al√©atoire.
* 1. Contexte et Enjeux
Avec la num√©risation croissante des infrastructures mondiales, le volume et la complexit√© des cyberattaques ont explos√© entre 2015 et 2024. Les m√©thodes traditionnelles de surveillance manuelles ne suffisent plus face √† la rapidit√© des attaques modernes. Ce projet vise √† exploiter l'Intelligence Artificielle pour renforcer la s√©curit√© des r√©seaux en automatisant la d√©tection des intrusions.

2. Objectifs du Projet
L'objectif principal est de d√©velopper un mod√®le de Machine Learning (Apprentissage Supervis√©) capable de :

-Analyser les logs de trafic r√©seau historiques.

-Identifier les mod√®les (patterns) suspects.

-Classifier avec pr√©cision le type d'attaque (Malware, DDoS, Phishing, Intrusion, etc.) ou de d√©terminer si le trafic est b√©nin.

3. Les Donn√©es (Dataset)
Le projet s'appuie sur le jeu de donn√©es Global Cybersecurity Threats, couvrant une p√©riode de 9 ans (2015-2024).

Source : Kaggle (Auteur : Atharva Soundankar).

Volume : Donn√©es structur√©es repr√©sentant des √©v√©nements de cybers√©curit√©.

Variables Cl√©s (Features) : Le dataset contient probablement des informations techniques telles que les adresses IP (source/destination), les ports, les protocoles utilis√©s, la g√©olocalisation, et l'horodatage.

Cible (Target) : La cat√©gorie de l'attaque (ex: 'Ransomware', 'Botnet', 'Benign', etc.).

4. M√©thodologie Technique
Le projet suit un pipeline de Data Science rigoureux :
Exploration et Nettoyage (EDA & Cleaning) :
Gestion des valeurs manquantes et des donn√©es bruit√©es.
Analyse statistique de la r√©partition des attaques (d√©s√©quilibre des classes).
Visualisation des corr√©lations pour identifier les variables les plus influentes.
Pr√©traitement (Preprocessing) :
Encodage : Transformation des variables cat√©gorielles (ex: Protocoles) en format num√©rique via One-Hot Encoding.
Normalisation : Mise √† l'√©chelle des donn√©es num√©riques si n√©cessaire.
Mod√©lisation (Modeling) :
Utilisation de l'algorithme Random Forest Classifier.
Choix de cet algorithme pour sa robustesse face au sur-apprentissage et sa capacit√© √† g√©rer un grand nombre de variables et de classes.
Gestion du d√©s√©quilibre des classes (param√®tre class_weight='balanced').

5. R√©sultats et √âvaluation
La performance du mod√®le est √©valu√©e via plusieurs m√©triques :
Accuracy : Taux global de bonnes pr√©dictions.
Matrice de Confusion : Pour visualiser les erreurs de classification entre les diff√©rents types d'attaques (ex: confondre un DDoS avec du trafic normal).
Feature Importance : Identification des facteurs techniques (ex: Port de destination) qui sont les plus d√©terminants pour pr√©dire une attaque.

6. Impact Business
Ce mod√®le permettrait √† une √©quipe SOC (Security Operations Center) de :
R√©duire le temps de r√©action face √† une menace.
Diminuer les "faux positifs" (fausses alertes).
Prioriser les interventions sur les attaques les plus critiques.


## 2. Le Code Python (Laboratoire)
Le notebook suit la structure standard "Paillasse de laboratoire" :
C'est une excellente initiative. Pour respecter rigoureusement la structure p√©dagogique du fichier "Correction Projet.md" (style "Paillasse de laboratoire"), j'ai r√©organis√© ton code.

J'ai conserv√© toute la logique sp√©cifique √† ton dataset de Cybers√©curit√© (gestion des 72 classes, encodage One-Hot, imputation mixte) mais je l'ai habill√©e avec les commentaires, les √©tapes num√©rot√©es et les affichages "pas √† pas" typiques du fichier de correction.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-Learn
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import plot_tree

# Configuration esth√©tique
sns.set_theme(style="whitegrid", palette="muted")
plt.rcParams['figure.figsize'] = (12, 6)
import warnings
warnings.filterwarnings('ignore')

# 1. CONFIGURATION ET CHARGEMENT 

print("--- √âTAPE 1 : CHARGEMENT DES DONN√âES ---")

# Mettez √† False pour utiliser votre vrai fichier CSV
USE_SYNTHETIC_DATA = True 
FILE_PATH = '/content/drive/MyDrive/CHEMIN/VERS/VOTRE/FICHIER.csv'

if USE_SYNTHETIC_DATA:
    print("MODE D√âMO : G√©n√©ration de donn√©es synth√©tiques...")
    from sklearn.datasets import make_classification
    # On g√©n√®re 1000 lignes, 20 colonnes, et 5 classes pour l'exemple
    X_raw, y_raw = make_classification(n_samples=1000, n_features=20, n_informative=15, 
                                       n_redundant=5, n_classes=5, random_state=42)
    df = pd.DataFrame(X_raw, columns=[f'Feature_{i}' for i in range(1, 21)])
    df['target'] = y_raw
    # On ajoute des noms de classes plus "r√©els"
    class_map = {0: 'Benign', 1: 'Malware', 2: 'Phishing', 3: 'DDoS', 4: 'Spyware'}
    df['target'] = df['target'].map(class_map)
    
else:
    try:
        df = pd.read_csv(FILE_PATH)
        print("Fichier charg√© avec succ√®s.")
    except FileNotFoundError:
        print(f"ERREUR : Fichier non trouv√© √† {FILE_PATH}. V√©rifiez le chemin.")
        # Arr√™t forc√© si pas de fichier
        raise

# Renommage cible si n√©cessaire
if df.columns[-1] != 'target' and 'target' not in df.columns:
    df.rename(columns={df.columns[-1]: 'target'}, inplace=True)

print(f"Taille du dataset : {df.shape}")
print(f"Classes d√©tect√©es : {df['target'].unique()}\n")

# 2. PR√âTRAITEMENT OPTIMIS√â

print("--- √âTAPE 2 : NETTOYAGE ET PR√âPARATION ---")

# S√©paration
X = df.drop('target', axis=1)
y = df['target']

# Introduction artificielle de bruit (seulement si d√©mo)
if USE_SYNTHETIC_DATA:
    mask = np.random.random(X.shape) < 0.05
    X = X.mask(mask) # Introduit des NaN

# Identification des types de colonnes
num_cols = X.select_dtypes(include=np.number).columns
cat_cols = X.select_dtypes(exclude=np.number).columns

# Imputation (Remplissage des trous)
if len(num_cols) > 0:
    imp_num = SimpleImputer(strategy='mean')
    X[num_cols] = imp_num.fit_transform(X[num_cols])

if len(cat_cols) > 0:
    imp_cat = SimpleImputer(strategy='most_frequent')
    X[cat_cols] = imp_cat.fit_transform(X[cat_cols])
    # Encodage One-Hot pour les variables cat√©gorielles (Features)
    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)

# Encodage de la Cible (Target) si c'est du texte
le = LabelEncoder()
y_encoded = le.fit_transform(y)
target_names = [str(cls) for cls in le.classes_]

# Split Train/Test
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)
# Note: 'stratify' est crucial pour garder la m√™me proportion de classes dans le train et le test

print("Donn√©es pr√™tes pour l'entra√Ænement.\n")

# 3. MOD√âLISATION (Random Forest)

print("--- √âTAPE 3 : ENTRA√éNEMENT DU MOD√àLE ---")

# Am√©lioration : class_weight='balanced' aide si certaines attaques sont rares
model = RandomForestClassifier(n_estimators=100, 
                               random_state=42, 
                               class_weight='balanced',
                               n_jobs=-1) # Utilise tous les c≈ìurs du processeur

model.fit(X_train, y_train)
print("Mod√®le entra√Æn√©.\n")

# 4. √âVALUATION ET DIAGRAMMES

print("--- √âTAPE 4 : VISUALISATION DES R√âSULTATS ---")

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"ACCURACY : {acc*100:.2f}%")

#  DIAGRAMME 1 : MATRICE DE CONFUSION 
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)
# Normalisation par ligne pour voir les pourcentages d'erreur par classe
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=target_names, yticklabels=target_names)
plt.title('Matrice de Confusion (Valeurs Absolues)')
plt.ylabel('Vraie Classe')
plt.xlabel('Classe Pr√©dite')
plt.show()

#  DIAGRAMME 2 : IMPORTANCE DES FEATURES 
# C'est crucial pour comprendre QUELLES colonnes permettent de d√©tecter l'attaque
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
# On garde le Top 15 pour la lisibilit√©
top_n = 15
indices = indices[:top_n]

plt.figure(figsize=(12, 6))
plt.title(f"Top {top_n} des Variables les plus Importantes (Feature Importance)")
plt.bar(range(top_n), importances[indices], align="center", color=sns.color_palette("viridis", top_n))
plt.xticks(range(top_n), [X.columns[i] for i in indices], rotation=45, ha='right')
plt.xlim([-1, top_n])
plt.tight_layout()
plt.show()

#  DIAGRAMME 3 : VISUALISATION D'UN ARBRE UNIQUE 
# Pour voir "comment le mod√®le pense"
plt.figure(figsize=(20, 10))
# On prend le premier arbre de la for√™t (index 0)
# On limite la profondeur (max_depth=3) pour que ce soit lisible √† l'√©cran
plot_tree(model.estimators_[0], 
          feature_names=X.columns,
          class_names=target_names,
          filled=True, 
          rounded=True, 
          max_depth=3,
          fontsize=10)
plt.title("Visualisation simplifi√©e d'un arbre de d√©cision de la for√™t")
plt.show()

1.  **Acquisition :** Chargement de 3000 lignes.
2.  **Simulation d'erreurs :** Introduction artificielle de valeurs manquantes (NaN) dans 1350 cellules pour tester la robustesse du nettoyage.
3.  **Nettoyage & Imputation :** Traitement diff√©renci√© des variables num√©riques et cat√©gorielles.
4.  **Mod√©lisation & √âvaluation :** Entra√Ænement du mod√®le et visualisation de la performance sur 72 classes.

---

## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

### La M√©canique de l'Imputation dans ce Notebook
Le notebook a d√ª g√©rer deux types de donn√©es, contrairement au projet m√©dical purement num√©rique :
1.  **Imputation Num√©rique :** Pour des colonnes comme `Financial Loss`, le code a utilis√© la **Moyenne** (Mean). Les trous ont √©t√© bouch√©s par la valeur moyenne calcul√©e (~50.63 Millions $).
2.  **Imputation Cat√©gorielle :** Pour les colonnes textuelles (ex: type d'attaque), le code a utilis√© le **Mode** (la valeur la plus fr√©quente).

###  Le Coin de l'Expert (Data Leakage)
*Observation Critique :* Dans le notebook, le nettoyage (√âtape 4) semble avoir √©t√© effectu√© sur l'ensemble du dataset *avant* le split Train/Test.
* **Verdict :** Il y a un risque de **Data Leakage**. En calculant la moyenne des pertes financi√®res sur les 3000 lignes (y compris celles qui serviront au test), le mod√®le a "trich√©" en voyant indirectement des informations du futur. Dans un environnement de production strict, il faudrait `fit` l'imputer uniquement sur le Train Set.

---

## 4. Analyse Approfondie : Exploration (EDA)

L'analyse des statistiques descriptives (√©tape 5 du notebook) r√©v√®le la structure des donn√©es :

### D√©crypter `.describe()`
* **Sym√©trie Parfaite (Distribution Normale ?) :**
    * Pour `Financial Loss`, la Moyenne est de **50.63** et la M√©diane (50%) est de **50.63**.
    * Pour `Affected Users`, la Moyenne est de **503,899** et la M√©diane est de **503,899**.
* **Interpr√©tation :** Contrairement aux donn√©es m√©dicales souvent asym√©triques (skewed), ces donn√©es (probablement simul√©es ou tr√®s √©quilibr√©es) suivent une distribution parfaitement sym√©trique. Il n'y a pas d'outliers massifs qui tirent la moyenne vers le haut.
* **Dispersions (Std) :** Les √©carts-types sont significatifs (28M$ de perte), indiquant une grande vari√©t√© dans la gravit√© des attaques, ce qui est une bonne nouvelle pour l'apprentissage du mod√®le (il a de la variance √† expliquer).

---

## 5. Analyse Approfondie : M√©thodologie (Split)

Le protocole exp√©rimental reste le garant de la g√©n√©ralisation. Avec 3000 lignes et 72 classes, le split (probablement 80/20 standard) laisse environ 600 exemples pour le test.
* **Le D√©fi Multiclasse :** Avec 72 classes, certaines classes peuvent √™tre rares. Un split al√©atoire simple (`train_test_split`) risque de ne mettre *aucun* exemple d'une classe rare dans le jeu d'entra√Ænement. Une s√©paration **stratifi√©e** (`stratify=y`) serait ici fortement recommand√©e pour s'assurer que le mod√®le voit au moins une fois chaque type de menace.

---

## 6. FOCUS TH√âORIQUE : L'Algorithme Random Forest üå≤

Dans ce contexte de cybers√©curit√© avec des donn√©es mixtes (cat√©gorielles et num√©riques) et un grand nombre de classes :

### La Pertinence du Random Forest
* **Robustesse aux dimensions :** Avec 72 classes en sortie, un arbre de d√©cision unique serait gigantesque et ferait du sur-apprentissage (overfitting) massif.
* **Le Bagging √† la rescousse :** En moyennant les d√©cisions de plusieurs arbres, le Random Forest lisse les fronti√®res de d√©cision. Si un arbre se trompe sur une cyber-attaque sp√©cifique (ex: confondre un Malware Russe avec un Phishing Chinois), les autres arbres peuvent corriger le tir par vote majoritaire.

---

## 7. Analyse Approfondie : √âvaluation (L'Heure de V√©rit√©)

### A. La Matrice de Confusion (72x72)
La visualisation g√©n√©r√©e dans le notebook (`sns.heatmap`) est une grille massive de 72x72 cases.
* **Diagonale :** Les cases sur la diagonale repr√©sentent les **Succ√®s** (Attaque pr√©dite = Attaque r√©elle).
* **Hors Diagonale :** Tout le reste est du bruit.
* **Lecture :** Contrairement au cas binaire (4 cases), on cherche ici des "clusters" d'erreurs. Par exemple, le mod√®le confond-il souvent les attaques "Ransomware" avec "Malware" ?

### B. Les M√©triques Avanc√©es (Adaptation Multiclasse)
* **Accuracy (Pr√©cision Globale) :** Avec 72 classes, une accuracy de 50% serait en r√©alit√© excellente (le hasard ferait 1/72 ‚âà 1.4%). Il ne faut donc pas juger ce chiffre avec les standards du binaire (o√π 50% est nul).
* **Pr√©cision & Rappel (Macro/Weighted Average) :**
    * Si le **Rappel** est bas pour une classe critique (ex: "Attaque √âtatique"), cela signifie que le syst√®me de d√©fense laisse passer des menaces majeures sans les d√©tecter.
    * Si la **Pr√©cision** est basse, le syst√®me g√©n√®re trop de fausses alertes, noyant les analystes de s√©curit√© sous du bruit (fatigue d'alerte).


